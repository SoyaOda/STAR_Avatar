"""
PyTorch Dataset for Synthetic STAR Training Data

Loads synthetic data generated by generate_synthetic_data.py:
- Multi-channel front/back views (Normal + Depth + Joints + Mask)
- Ground truth beta (shape parameters)
- Ground truth T (global translation)
- Optional user attributes (height, weight, gender)
"""

import os
import numpy as np
import torch
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms


class SyntheticDataset(Dataset):
    """
    Dataset for synthetic STAR body data.

    Directory structure expected:
        outputs/synthetic_data/
        ├── sample_1/
        │   ├── front_normal.png
        │   ├── front_depth.png
        │   ├── front_joints_heatmap.png
        │   ├── front_mask.png
        │   ├── back_normal.png
        │   ├── back_depth.png
        │   ├── back_joints_heatmap.png
        │   ├── back_mask.png
        │   ├── beta_gt.npy (shape: [10])
        │   └── T_gt.npy (shape: [3])
        ├── sample_2/
        └── ...
    """

    def __init__(self, data_dir='outputs/synthetic_data', transform=None,
                 use_attributes=False, image_size=512):
        """
        Initialize synthetic dataset.

        Args:
            data_dir: Root directory containing sample folders
            transform: Optional transform to apply to images
            use_attributes: Whether to include user attributes (height/weight/gender)
            image_size: Expected image size (default: 512)
        """
        self.data_dir = data_dir
        self.transform = transform
        self.use_attributes = use_attributes
        self.image_size = image_size

        # Get list of sample directories
        self.samples = []
        if os.path.exists(data_dir):
            for item in sorted(os.listdir(data_dir)):
                sample_path = os.path.join(data_dir, item)
                if os.path.isdir(sample_path) and item.startswith('sample_'):
                    # Check if all required files exist
                    if self._validate_sample(sample_path):
                        self.samples.append(sample_path)

        if len(self.samples) == 0:
            raise ValueError(f"No valid samples found in {data_dir}")

        print(f"Loaded {len(self.samples)} samples from {data_dir}")

    def _validate_sample(self, sample_path):
        """Check if sample has all required files."""
        required_files = [
            'front_normal.png',
            'front_depth.png',
            'front_joints_heatmap.png',
            'front_mask.png',
            'back_normal.png',
            'back_depth.png',
            'back_joints_heatmap.png',
            'back_mask.png',
            'beta_gt.npy',
            'T_gt.npy'
        ]

        for filename in required_files:
            if not os.path.exists(os.path.join(sample_path, filename)):
                return False
        return True

    def __len__(self):
        return len(self.samples)

    def _load_image(self, path):
        """Load image and convert to numpy array."""
        img = Image.open(path)
        return np.array(img, dtype=np.float32) / 255.0  # Normalize to [0, 1]

    def _load_multichannel_view(self, sample_path, view='front'):
        """
        Load and stack multi-channel input for one view.

        Args:
            sample_path: Path to sample directory
            view: 'front' or 'back'

        Returns:
            Tensor of shape [21, H, W]:
                - Normal map: channels 0-2 (RGB)
                - Depth map: channel 3 (grayscale)
                - Mask: channel 4 (grayscale)
                - Joint heatmaps: channels 5-20 (16 joints, grayscale each)
        """
        # Load normal map (RGB, 3 channels)
        normal_path = os.path.join(sample_path, f'{view}_normal.png')
        normal = self._load_image(normal_path)  # [H, W, 3]

        # Load depth map (grayscale, 1 channel)
        depth_path = os.path.join(sample_path, f'{view}_depth.png')
        depth = self._load_image(depth_path)  # [H, W] or [H, W, 1]
        if depth.ndim == 3:
            depth = depth[:, :, 0]  # Take first channel if RGB
        depth = np.expand_dims(depth, axis=2)  # [H, W, 1]

        # Load mask (grayscale, 1 channel)
        mask_path = os.path.join(sample_path, f'{view}_mask.png')
        mask = self._load_image(mask_path)  # [H, W] or [H, W, 1]
        if mask.ndim == 3:
            mask = mask[:, :, 0]
        mask = np.expand_dims(mask, axis=2)  # [H, W, 1]

        # Load joint heatmaps (16 channels stacked as RGB image)
        joints_path = os.path.join(sample_path, f'{view}_joints_heatmap.png')
        joints_img = self._load_image(joints_path)  # [H, W] or [H, W, 3]

        # The joints heatmap was saved as a visualization (grayscale or RGB)
        # For training, we need the actual 16-channel heatmaps
        # Since we saved it as visualization, we'll use grayscale as proxy
        # TODO: Modify generate_synthetic_data.py to save individual heatmaps
        # For now, replicate the grayscale across 16 channels
        if joints_img.ndim == 3:
            joints_gray = np.mean(joints_img, axis=2, keepdims=True)  # [H, W, 1]
        else:
            joints_gray = np.expand_dims(joints_img, axis=2)  # [H, W, 1]
        joints = np.repeat(joints_gray, 16, axis=2)  # [H, W, 16]

        # Stack all channels: Normal(3) + Depth(1) + Mask(1) + Joints(16) = 21
        multichannel = np.concatenate([normal, depth, mask, joints], axis=2)  # [H, W, 21]

        # Convert to torch tensor and change to [C, H, W] format
        multichannel = torch.from_numpy(multichannel).float()  # [H, W, 21]
        multichannel = multichannel.permute(2, 0, 1)  # [21, H, W]

        return multichannel

    def __getitem__(self, idx):
        """
        Get one sample.

        Returns:
            dict with keys:
                - 'front_input': Tensor [21, H, W]
                - 'back_input': Tensor [21, H, W]
                - 'beta_gt': Tensor [10]
                - 'T_gt': Tensor [3]
                - 'attr_input': Optional Tensor [3] (if use_attributes=True)
        """
        sample_path = self.samples[idx]

        # Load multi-channel inputs
        front_input = self._load_multichannel_view(sample_path, 'front')
        back_input = self._load_multichannel_view(sample_path, 'back')

        # Load ground truth
        beta_gt = np.load(os.path.join(sample_path, 'beta_gt.npy'))
        T_gt = np.load(os.path.join(sample_path, 'T_gt.npy'))

        beta_gt = torch.from_numpy(beta_gt).float().squeeze()  # Remove batch dim if present
        T_gt = torch.from_numpy(T_gt).float()

        # Apply transform if provided
        if self.transform is not None:
            # Apply same transform to both views
            # Note: transform should handle multi-channel input
            front_input = self.transform(front_input)
            back_input = self.transform(back_input)

        result = {
            'front_input': front_input,
            'back_input': back_input,
            'beta_gt': beta_gt,
            'T_gt': T_gt
        }

        # Add user attributes if requested
        if self.use_attributes:
            # For synthetic data, we can generate random attributes
            # or load from file if available
            # Format: [height_ratio, weight_ratio, gender]
            # For now, generate random attributes
            height_ratio = torch.rand(1) * 0.3 + 0.85  # [0.85, 1.15]
            weight_ratio = torch.rand(1) * 0.3 + 0.85  # [0.85, 1.15]
            gender = torch.randint(0, 2, (1,)).float()  # 0 or 1

            attr_input = torch.cat([height_ratio, weight_ratio, gender])
            result['attr_input'] = attr_input

        return result


def test_dataset():
    """Test the synthetic dataset."""
    print("="*60)
    print("Testing SyntheticDataset")
    print("="*60)

    # Check if synthetic data exists
    data_dir = 'outputs/synthetic_data'
    if not os.path.exists(data_dir):
        print(f"\nError: {data_dir} does not exist")
        print("Please run generate_synthetic_data.py first to create synthetic data")
        return

    # Create dataset
    try:
        dataset = SyntheticDataset(
            data_dir=data_dir,
            use_attributes=True
        )
    except ValueError as e:
        print(f"\nError: {e}")
        print("Please run generate_synthetic_data.py first to create synthetic data")
        return

    print(f"\nDataset size: {len(dataset)}")

    # Test loading one sample
    print("\nLoading first sample...")
    sample = dataset[0]

    print(f"\nSample keys: {sample.keys()}")
    print(f"\nShapes:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}")

    print(f"\nValue ranges:")
    print(f"  front_input: [{sample['front_input'].min():.3f}, {sample['front_input'].max():.3f}]")
    print(f"  back_input: [{sample['back_input'].min():.3f}, {sample['back_input'].max():.3f}]")
    print(f"  beta_gt: {sample['beta_gt'].numpy()}")
    print(f"  T_gt: {sample['T_gt'].numpy()}")
    if 'attr_input' in sample:
        print(f"  attr_input: {sample['attr_input'].numpy()}")

    # Test DataLoader
    print("\n" + "-"*60)
    print("Testing with DataLoader")
    print("-"*60)

    from torch.utils.data import DataLoader

    dataloader = DataLoader(
        dataset,
        batch_size=4,
        shuffle=True,
        num_workers=0
    )

    print(f"\nDataLoader batch count: {len(dataloader)}")

    # Load one batch
    batch = next(iter(dataloader))

    print(f"\nBatch shapes:")
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}")

    print("\n" + "="*60)
    print("✓ Dataset test passed!")
    print("="*60)


if __name__ == "__main__":
    test_dataset()
